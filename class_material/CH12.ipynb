{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23c6041",
   "metadata": {},
   "source": [
    "# 卷積神經網路實作(LeNet-5實作)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfa891",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c437b",
   "metadata": {},
   "source": [
    "(1) 載入資料：TensorFlow中自MNIST手寫數字識別圖像數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21852f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "# 將資料做一個歸一化的動作\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = tf.reshape(x,[28,28,1])\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "batchs = 32\n",
    "\n",
    "# 載入mnist 資料集 60000張訓練資料 , 10000張測試資料, 每張大小為 28x28\n",
    "(train_Data, train_Label), (test_Data, test_Label) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b731d86",
   "metadata": {},
   "source": [
    "(2) 資料打散與封裝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將訓練集資料打散\n",
    "db = tf.data.Dataset.from_tensor_slices((train_Data, train_Label))\n",
    "db = db.map(preprocess).shuffle(10000).batch(batchs) # 打散後包裝成批\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((test_Data, test_Label))\n",
    "db_test = db_test.map(preprocess).batch(batchs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3f05f2",
   "metadata": {},
   "source": [
    "(3) 模型建置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf9178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型建置\n",
    "LeNet5Model = Sequential([\n",
    "    # 第一個卷積層，6個 5x5 卷積核,激勵函數為 relu\n",
    "    Conv2D(6,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
    "    # 池化層大小 2x2, 步長 2\n",
    "    MaxPooling2D(pool_size=2,strides=2),\n",
    "    # 第二個卷積層，16個 5x5 卷積核, 步長為 1\n",
    "    Conv2D(16,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
    "    # 池化層大小 2x2, 步長 2\n",
    "    MaxPooling2D(pool_size=2,strides=2),\n",
    "    # 打平層，方便全連接層處理\n",
    "    Flatten(),\n",
    "    # 全連接層，120 個節點, 激勵函數為 relu\n",
    "    Dense(120, activation='relu'),\n",
    "    # 全連接層，84 個節點, 激勵函數為 relu\n",
    "    Dense(84, activation='relu'),\n",
    "    # 全連接層(輸出)，10 個節點, 最後以機率方式呈現\n",
    "    Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定輸入數據維度\n",
    "LeNet5Model.build(input_shape=(None, 28, 28, 1))\n",
    "# 顯示參數量\n",
    "print(LeNet5Model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844795d",
   "metadata": {},
   "source": [
    "(4) 設定優化器與編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d06135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定優化器\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "# 配置模型  # label 為數字編碼\n",
    "LeNet5Model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',  # 指定損失函數\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2a11a",
   "metadata": {},
   "source": [
    "(5) 訓練模型並追蹤正確率與損失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a436c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練模型\n",
    "hist = LeNet5Model.fit(db,epochs=5, validation_data=db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b69ea1",
   "metadata": {},
   "source": [
    "# AlexNet網路實作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632fbadf",
   "metadata": {},
   "source": [
    "(1) 下載資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "# 載入 cifar10 資料集 50000張訓練資料 , 10000張測試資料, 每張大小為 32x32,3通道\n",
    "(train_Data, train_Label), (test_Data, test_Label) = cifar10.load_data()\n",
    "print(\"train_Data.shape\",train_Data.shape)\n",
    "print(\"train_Label.shape\",train_Label.shape)\n",
    "print(\"test_Data.shape\",test_Data.shape)\n",
    "print(\"test_Label.shape\",test_Label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a04663",
   "metadata": {},
   "source": [
    "(2) 數據分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料切割, 訓練資料的前面 5000 筆當作是驗證集, 剩下的為測試集\n",
    "validation_data, validation_label = train_Data[:5000],train_Label[:5000]\n",
    "train_Data,train_Label= train_Data[5000:],train_Label[5000:]\n",
    "# 印出訓練資料與驗證資料大小\n",
    "print(\"train_Data.shape\",train_Data.shape)\n",
    "print(\"validation_data.shape\",validation_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674a1b5",
   "metadata": {},
   "source": [
    "(3) 資料合成與顯示資料及影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "CLASS_NAME=[\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\n",
    "            \"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_Data,train_Label))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_Data, test_Label))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_data,\n",
    "                                                    validation_label))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "# 顯示前九張資料影像\n",
    "for i,(image,label) in enumerate(train_ds.take(9)):\n",
    "    ax = plt.subplot(3,3,1+i)\n",
    "    plt.imshow(image)\n",
    "    plt.title(CLASS_NAME[label.numpy()[0]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c94de1",
   "metadata": {},
   "source": [
    "(4) 資料預處理：資料大小轉換與標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533abfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    image = tf.image.resize(image,(227,227))\n",
    "    return image,label\n",
    "\n",
    "batch_size = 20 #原定360\n",
    "# 訓練集資料需要打散(shuffle)，打散後分包(batch)\n",
    "train_ds = train_ds.map(preprocess).shuffle(1000).batch(batch_size=batch_size)\n",
    "# 驗證集與測試集資料不用打散\n",
    "validation_ds = validation_ds.map(preprocess).batch(batch_size=batch_size)\n",
    "test_ds = test_ds.map(preprocess).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0fc0d8",
   "metadata": {},
   "source": [
    "(5) 網路設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35567dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, \\\n",
    "    Flatten,BatchNormalization,Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    # 第一層  卷積層 + BN 層 + 最大池化層\n",
    "    # filters=48+48=96\n",
    "    Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),\n",
    "           activation='relu',input_shape=(227,227,3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(3,3),strides=(2,2)),\n",
    "    # 第二層  卷積層 + BN 層 + 最大池化層\n",
    "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1),\n",
    "           activation='relu',padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    # 第三層  卷積層 + BN 層\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1),\n",
    "           activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    # 第四層  卷積層 + BN 層\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1),\n",
    "           activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    # 第五層  卷積層 + BN 層 + 最大池化層\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1),\n",
    "           activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    # 展開層    \n",
    "    Flatten(),     \n",
    "    Dense(4096,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf6ebb",
   "metadata": {},
   "source": [
    "(6) 編譯與訓練網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75520742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編譯與訓練網路\n",
    "model.compile(optimizer= 'adam',loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "History = model.fit(train_ds,epochs=5,validation_data=validation_ds,   #epochs原定30\n",
    "                    validation_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10348e",
   "metadata": {},
   "source": [
    "(7) 評估測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a345f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評估網路\n",
    "loss, acc = model.evaluate(test_ds, verbose=0)\n",
    "print(\"Test loss :\", loss)\n",
    "print(\"Test accuracy :\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
