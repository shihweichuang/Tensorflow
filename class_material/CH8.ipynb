{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59de8531",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7bcae",
   "metadata": {},
   "source": [
    "# 利用Keras提供的API建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "# 匯入Keras的mnist模組\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_Data, train_Label), (test_Data, test_Label) = mnist.load_data()\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),   # 將輸入資料從 28x28 攤平成 784，另攤平不用計算權重\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax') # output 為 10 個 class\n",
    "])\n",
    "\n",
    "# model 每層定義好後需要經過 compile\n",
    "# sparse_categorical_crossentropy 的標籤是 integer\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 訓練：將建立好的 model 去 fit 我們的 training data\n",
    "model.fit(train_Data, train_Label, epochs=10)\n",
    "# 評估：利用 test_Data 去進行模型評估\n",
    "# verbose = 2 為每個 epoch 輸出一行紀錄\n",
    "model.evaluate(test_Data, test_Label, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b45ab",
   "metadata": {},
   "source": [
    "# compile函數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6225c5",
   "metadata": {},
   "source": [
    "法一：傳遞預定優化器名稱至compile函數，在此情形下，優化器的參數將使用默認值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8ade6",
   "metadata": {},
   "source": [
    "法二：初始化一個優化器對象，然後傳入該函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25174936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers            # 匯入優化模組\n",
    "sgd = optimizers.SGD(lr = 0.01, momentum = 0.9)    # 先設定優化器名稱\n",
    "model.compile(optimizer = sgd,                     # 選擇優化器：指定優化函式，可直接輸入sgd\n",
    "              loss='mse',                          # 設定損失函數\n",
    "              metrics=['acc'])                     # 設定成效衡量指標"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bc518d",
   "metadata": {},
   "source": [
    "法三：或者也可以直接把優化函數代入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01, momentum = 0.9)\n",
    "model.compile(optimizer = optimizers.SGD(lr = 0.01, momentum = 0.9),\n",
    "              loss='mse', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec74e4",
   "metadata": {},
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc24d0",
   "metadata": {},
   "source": [
    "方法一：直接使用字串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae', 'acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017e5241",
   "metadata": {},
   "source": [
    "方法二：使用 tf.keras.metrics 下的類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8855bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics\n",
    "\n",
    "model.compile(optimizer = 'sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[metrics.mae, metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1a6105",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d5b78",
   "metadata": {},
   "source": [
    "改寫程式CH8_1內model.compile()函式內的 metrics 參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340178d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics\n",
    "# model 每層定義好後需要經過 compile\n",
    "# sparse_categorical_crossentropy 的標籤是 integer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc','mse',metrics.sparse_categorical_crossentropy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942bae82",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce24a5",
   "metadata": {},
   "source": [
    "# 載入資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de237eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# 加載，預處理數據集\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# 前8個為資料集，第9個為標籤\n",
    "data = dataset[:, 0:8]    # 資料集\n",
    "label = dataset[:, 8]     # 標籤\n",
    "\n",
    "print(\"data.shape : \", data.shape)   # 印出資料集的維度\n",
    "print(\"label.shape : \",label.shape)  # 印出標籤維度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2903fecb",
   "metadata": {},
   "source": [
    "# 創造網路模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ef3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# add加入資料\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) # 第3層 結果：有沒有得到糖尿病 / sigmoid介於0~1\n",
    "\n",
    "print(model.summary())  # 印出網路資訊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132b5810",
   "metadata": {},
   "source": [
    "# 編譯與訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33236d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編譯模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 分成訓練集、驗證集(用於告訴模型何時可以停止)、測試集\n",
    "# 驗證集不影響權重，只有訓練集會影響權重\n",
    "# 訓練模型   迭代100次、批處理大小為10,\n",
    "history = model.fit(data, label, epochs=100, batch_size=10,\n",
    "                    validation_split = 0.2,    # 劃分資料集的20%作為驗證集用(真正測試只有80%)\n",
    "                    verbose = 2)               # 印出為精簡模式\n",
    "print(\"history: \",history.history)             # 印出歷史紀錄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676c69a",
   "metadata": {},
   "source": [
    "# 模型評估與預測模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48978ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評估模型\n",
    "loss, accuracy = model.evaluate(data, label)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "# 數據預測\n",
    "probabilities = model.predict(data)\n",
    "# 將 probabilities 的輸出值透過np.round()做四捨五入\n",
    "predictions = [float(np.round(x)) for x in probabilities]\n",
    "# 計算預測結果跟真實結果的平均差距\n",
    "accuracy = np.mean(predictions == label)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282929fe",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3822b818",
   "metadata": {},
   "source": [
    "# Early stopping(提前停止)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c89800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "# 匯入Keras 的 mnist模組\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_Data, train_Label), (test_Data, test_Label) = mnist.load_data()\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),   # 將輸入資料從 28x28 攤平成 784\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # output 為 10 個 class\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義訓練的步驟數目\n",
    "NUM_EPOCHS = 100\n",
    "# model 每層定義好後需要經過 compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss= 'sparse_categorical_crossentropy',\n",
    "              metrics=['acc',metrics.mse,\n",
    "                       metrics.sparse_top_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe8b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 tf.keras.EarlyStopping 回調函數\n",
    "# 並指名監控的對象 => val_sparse_top_k_categorical_accuracy\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_sparse_top_k_categorical_accuracy', min_delta=0.001,\n",
    "  patience=1, verbose=1, mode='auto')  \n",
    "# min_delta=0.001 => 與前一次差異不到0.001就停止\n",
    "# patience 平常不會寫1，訓練時不應該這樣做\n",
    "# verbose 秀訊息 \n",
    "# mode 看目前的監看對象是誰(可設定min, max, auto)\n",
    "\n",
    "# 將建立好的 model 去 fit 我們的 training data\n",
    "model.fit(train_Data, train_Label,\n",
    "          validation_split = 0.2,    # 劃分資料集的 20% 作為驗證集用\n",
    "          epochs=NUM_EPOCHS,\n",
    "\t\t\t\t\tcallbacks=[earlystop_callback])\n",
    "# 利用 test_Data 去進行模型評估\n",
    "# verbose = 2 為每個 epoch 輸出一行紀錄\n",
    "model.evaluate(test_Data, test_Label, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414d5352",
   "metadata": {},
   "source": [
    "# sparse_top_k_categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd64e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "y_true = [2, 1, 1, 0]  # 假設四個樣本\n",
    "y_pred = [[0.3, 0.6, 0.1], [0.5, 0.4, 0.1], [0.3, 0.6, 0.1], [0.9, 0., 0.1]]\n",
    "m = tf.keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
    "print(m.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a38563",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a878b37",
   "metadata": {},
   "source": [
    "使用Fashion MNIST來當範例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9111a22",
   "metadata": {},
   "source": [
    "# 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba76f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(train_image,train_label),(test_image,test_label)=\\\n",
    "    tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(\"train_image : \",train_image.shape)\n",
    "print(\"train_label : \",train_label.shape)\n",
    "print(\"test_image : \",test_image.shape)\n",
    "print(\"test_label : \",test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a15da",
   "metadata": {},
   "source": [
    "# 將資料集中的前面9筆資料圖片印出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101317de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "              'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle boot']\n",
    "# 顯示指定的影像 (這裡顯示九張)\n",
    "def ShowImage(x,y):\n",
    "    for i in range(9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(x[i], cmap=plt.get_cmap('gray'))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.xlabel(class_names[y[i]])\n",
    "    plt.show()\n",
    "\n",
    "ShowImage(train_image,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa0382",
   "metadata": {},
   "source": [
    "# 資料初始化與建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對資料集做一個前置處理, 將資料正規到 0~1 之間 # 好處為把數值集中(不那麼分散)\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "# 建立模型\n",
    "def build_model():\n",
    "    # 線性疊加\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # 改變平坦輸入\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    # 第一層隱藏層, 包含256個神經元\n",
    "    model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "    # 第二層隱藏層, 包含128個神經元\n",
    "    model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "    # 第三層隱藏層, 包含256個神經元\n",
    "    model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "    # 第四層為輸出層分 10 個類別\n",
    "    model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b898a",
   "metadata": {},
   "source": [
    "# 編譯與訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febbbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編譯模型 complie用於指定三個項目定義\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(),    # 優化函式\n",
    "              loss='sparse_categorical_crossentropy',   # 損失函式\n",
    "              metrics=['accuracy'])                     # 監控對象\n",
    "\n",
    "train_images, train_labels = preprocess(train_image, train_label)\n",
    "batchsz = 128  # 設定批次大小\n",
    "# 訓練模型 開始進行訓練\n",
    "history = model.fit(train_images, train_labels,epochs=100, # 6萬張影像各訓練100次\n",
    "                    batch_size = batchsz,   # 設定批次訓練大小\n",
    "                    validation_split = 0.2,    # 劃分資料集的 20% 作為驗證集用\n",
    "                    verbose = 2)  # 印出為精簡模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2df48",
   "metadata": {},
   "source": [
    "# 確認模型預測結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08899454",
   "metadata": {},
   "source": [
    "首先將測試資料的前十五筆資料印出並比對前十五筆資料的標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fadb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 測試資料的預處理\n",
    "test_image, test_labels = preprocess(test_image, test_label)\n",
    "predicted_image15 = model.predict(test_image[:15])       # 只先丟前15張進去測試\n",
    "predicted_ids15 = np.argmax(predicted_image15, axis=-1)  # argmax為取出機率最大的index，axis=-1 為最後資訊\n",
    "print(\"Predicted labels: \", predicted_ids15[:15])\n",
    "print(\"test labels: \", test_label[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae76f3eb",
   "metadata": {},
   "source": [
    "保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83837225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存網路\n",
    "model.save('Fashion_model.h5') # 存在相同資料夾\n",
    "print('Save Model')\n",
    "del model                      # 從專案中刪除模型，之後進行測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5de3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入模型\n",
    "print('loaded model from Fashion_model.h5')\n",
    "Model2 = tf.keras.models.load_model('Fashion_model.h5',compile=False) # 不做compile要設定為false(預設值為true)\n",
    "# 拿前十五筆資料來預測並印出標籤\n",
    "prediction = Model2.predict(test_image[:15])\n",
    "print(tf.argmax(prediction,1))\n",
    "# 印出前十五筆資料的正確標籤\n",
    "print(test_labels[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image = Model2.predict(test_image)  # 進行預測\n",
    "print(predicted_image.shape)\n",
    "predicted_ids = np.argmax(predicted_image, axis=-1)  # 取出機率最大的 index\n",
    "print(\"Predicted labels: \", predicted_ids)\n",
    "print(\"test labels: \", test_label)\n",
    "# 比較兩個 predicted_ids 與 test_label 是否相同\n",
    "correct_prediction = tf.equal(predicted_ids,test_label)  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6714684",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a960fff6",
   "metadata": {},
   "source": [
    "載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(train_image,train_label),(test_image,test_label)=\\\n",
    "    tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 對資料集做一個前置處理, 將資料正規到 0~1 之間\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "# 載入模型\n",
    "print('loaded model from Fashion_model.h5')\n",
    "test_image, test_labels = preprocess(test_image, test_label)\n",
    "# 不做compile要設定為false(預設值為true)\n",
    "Model2 = tf.keras.models.load_model('Fashion_model.h5',compile=False)\n",
    "# 拿前十五筆資料來預測並印出標籤\n",
    "prediction = Model2.predict(test_image[:15])\n",
    "print(\"Predicted labels:\", tf.argmax(prediction,1))\n",
    "# 印出前十五筆資料的正確標籤\n",
    "print(\"test labels: \",test_labels[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image = Model2.predict(test_image)  # 進行預測\n",
    "print(predicted_image.shape)\n",
    "predicted_ids = np.argmax(predicted_image, axis=-1)  # 取出機率最大的 index\n",
    "print(\"Predicted labels: \", predicted_ids)\n",
    "print(\"test labels: \", test_label)\n",
    "# 比較兩個 predicted_ids 與 test_label 是否相同\n",
    "correct_prediction = tf.equal(predicted_ids,test_label)  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a9af5",
   "metadata": {},
   "source": [
    "繼續訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(train_image,train_label),(test_image,test_label)=\\\n",
    "    tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 對資料集做一個前置處理, 將資料正規到 0~1 之間\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "train_image, train_label = preprocess(train_image, train_label)\n",
    "\n",
    "# 載入模型\n",
    "print('loaded model from Fashion_model.h5')\n",
    "ReloadModel = tf.keras.models.load_model('Fashion_model.h5')\n",
    "batchsz = 128                              # 設定批次大小\n",
    "ReloadModel.fit(train_image, train_label,epochs=10,\n",
    "                batch_size = batchsz,      # 設定批次訓練大小\n",
    "                validation_split = 0.2,    # 劃分資料集的 20% 作為驗證集用\n",
    "                verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f518023a",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676bb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(train_image,train_label),(test_image,test_label)=\\\n",
    "    tf.keras.datasets.fashion_mnist.load_data()\n",
    "# 對資料集做一個前置處理, 將資料正規到 0~1 之間\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "test_images, test_labels = preprocess(test_image, test_label)\n",
    "# 載入模型\n",
    "print('loaded model from Fashion_model.h5')\n",
    "ReloadModel = tf.keras.models.load_model('Fashion_model.h5')\n",
    "loss,accuracy = ReloadModel.evaluate(test_images,test_labels)\n",
    "# 列印損失值與正確率\n",
    "print(\"\\n test loss : \", loss)\n",
    "print(\"\\n test accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed5042",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "# 匯入Keras的mnist模組\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_Data, train_Label), (test_Data, test_Label) = mnist.load_data()\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),   # 將輸入資料從 28x28 攤平成 784\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # output 為 10 個 class\n",
    "])\n",
    "\n",
    "# model 每層定義好後需要經過 compile\n",
    "# sparse_categorical_crossentropy 的標籤是 integer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 將建立好的 model 去 fit 我們的 training data\n",
    "model.fit(train_Data, train_Label, epochs=10)    # fit一定要拿訓練資料\n",
    "# 利用 test_Data 去進行模型評估\n",
    "# verbose = 2 為每個 epoch 輸出一行紀錄\n",
    "model.evaluate(test_Data, test_Label, verbose=2) # 評估一定要拿測試資料\n",
    "\n",
    "# 模型權重保存\n",
    "print(\"save_weights\")\n",
    "model.save_weights('modelWeight.h5')\n",
    "del model\n",
    "\n",
    "# 重新定義模型結構\n",
    "model_2 = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),   # 將輸入資料從 28x28 攤平成 784\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # output 為 10 個 class\n",
    "])\n",
    "# 雖然得到權重，但還是要再加入優化函式、損失函式，才能進行評估\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_2.load_weights('modelWeight.h5')\n",
    "loss, accuracy = model_2.evaluate(test_Data, test_Label)\n",
    "print(\"\\n test loss:\",loss)\n",
    "print(\"\\n test accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825aa2fc",
   "metadata": {},
   "source": [
    "# 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "# 匯入Keras的mnist模組\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_Data, train_Label), (test_Data, test_Label) = mnist.load_data()\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),   # 將輸入資料從 28x28 攤平成 784\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # output 為 10 個 class\n",
    "])\n",
    "\n",
    "# model 每層定義好後需要經過 compile\n",
    "# sparse_categorical_crossentropy 的標籤是 integer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 將建立好的 model 去 fit 我們的 training data\n",
    "model.fit(train_Data, train_Label, epochs=10)\n",
    "# 利用 test_Data 去進行模型評估\n",
    "# verbose = 2 為每個 epoch 輸出一行紀錄\n",
    "model.evaluate(test_Data, test_Label, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 儲存網路至工作路徑底下的 temp 資料夾\n",
    "tf.saved_model.save(model,'temp')\n",
    "print('Save Model')\n",
    "# 刪除模型\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb769f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Load Model')\n",
    "# 從 temp 資料夾底下載入模型\n",
    "# ModelNew = tf.saved_model.load('temp')   # 有問題\n",
    "ModelNew = tf.keras.models.load_model('temp')\n",
    "categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "# 輸入測試資料\n",
    "y_pred = ModelNew(test_Data)\n",
    "\n",
    "# 利用 update_state() 設定更新真實值與預測值的數據\n",
    "categorical_accuracy.update_state(y_true=test_Label, y_pred=y_pred)\n",
    "# 執行結果\n",
    "print(\"Test Accuracy : \",categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f251a",
   "metadata": {},
   "source": [
    "# 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27346ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "# 匯入Keras的mnist模組\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_Data, train_Label), (test_Data, test_Label) = mnist.load_data()\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),   # 將輸入資料從 28x28 攤平成 784\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # output 為 10 個 class\n",
    "])\n",
    "\n",
    "# model 每層定義好後需要經過 compile\n",
    "# sparse_categorical_crossentropy 的標籤是 integer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='weights.{epoch:02d}-{val_accuracy:.4f}.h5',\n",
    "                                  monitor='val_accuracy',save_best_only=True,verbose=1)\n",
    "\n",
    "# 將建立好的 model 去 fit 我們的 training data\n",
    "history = model.fit(train_Data, train_Label, \n",
    "                    epochs=20, batch_size=512,\n",
    "                    validation_split=0.2,verbose=2,\n",
    "                    callbacks=[model_checkpoint])  # 添加 callback\n",
    "# 利用 test_Data 去進行模型評估\n",
    "# verbose = 2 為每個 epoch 輸出一行紀錄\n",
    "model.evaluate(test_Data, test_Label, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a89c1",
   "metadata": {},
   "source": [
    "# 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5895b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "# 匯入Keras的mnist模組\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_Data, train_Label), (test_Data, test_Label) = mnist.load_data()\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),   # 將輸入資料從 28x28 攤平成 784\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # output 為 10 個 class\n",
    "])\n",
    "\n",
    "# model 每層定義好後需要經過 compile\n",
    "# sparse_categorical_crossentropy 的標籤是 integer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.01,\n",
    "                               patience=0,verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(filepath='weights.{epoch:02d}-{val_accuracy:.4f}.h5',\n",
    "                                  monitor='val_accuracy',save_best_only=True,verbose=1)\n",
    "\n",
    "# 將建立好的 model 去 fit 我們的 training data\n",
    "history = model.fit(train_Data, train_Label, \n",
    "                    epochs=20, batch_size=500,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping, model_checkpoint])  # 添加 callback\n",
    "# 利用 test_Data 去進行模型評估\n",
    "# verbose = 2 為每個 epoch 輸出一行紀錄\n",
    "model.evaluate(test_Data, test_Label, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
